{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"colab":{"name":"models_exploration.ipynb","provenance":[],"collapsed_sections":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"bbe9c78b9d3b4090816e76eb76677776":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_eda0cf1487d440cfb910e8670fa45e9b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c8e2b385ee7949b68b94f594bf1c4701","IPY_MODEL_bf8e9f7eb1da4a7ca479ca7830507adb"]}},"eda0cf1487d440cfb910e8670fa45e9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c8e2b385ee7949b68b94f594bf1c4701":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_01152b8a64984744971fb30a68300df3","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4d03102170eb486e9cd849854e826e90"}},"bf8e9f7eb1da4a7ca479ca7830507adb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c0a3d6f59ca94f0dba41abcb6c78cb1f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:02&lt;00:00, 333kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3a85b6e5ce8541e487f4ee46c9ae60e2"}},"01152b8a64984744971fb30a68300df3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4d03102170eb486e9cd849854e826e90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c0a3d6f59ca94f0dba41abcb6c78cb1f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3a85b6e5ce8541e487f4ee46c9ae60e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4f92834a27be470391e6282648571eb8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ce4150e4ea724ae5ad6fddef7388aace","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_daf149fe5b66438fa0f1f959faf2ba1f","IPY_MODEL_b53c8e61bd724318a6838315f1515fe6"]}},"ce4150e4ea724ae5ad6fddef7388aace":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"daf149fe5b66438fa0f1f959faf2ba1f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c0c0df82976e4ec690d2a4cbc0ac552f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9a87e0dc73b34137a2fb369afe16e999"}},"b53c8e61bd724318a6838315f1515fe6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_08e9f664f2e148de810828f86bd88b6e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:01&lt;00:00, 243kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aee13d0d16c34798802d730a051fd6ed"}},"c0c0df82976e4ec690d2a4cbc0ac552f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9a87e0dc73b34137a2fb369afe16e999":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"08e9f664f2e148de810828f86bd88b6e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aee13d0d16c34798802d730a051fd6ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8ad3ad42c1df492bb8d0504a2c481024":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_32252d95ad7c4651975e3cee27ee4e9d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_66d839cabac145739b3e40f23bd1ed52","IPY_MODEL_a416fadcb9fb4156afca5c174eccab3f"]}},"32252d95ad7c4651975e3cee27ee4e9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"66d839cabac145739b3e40f23bd1ed52":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a071a26bcc314b9282ac1c347002bf74","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ddc9f8a82c104ae8866517ab56176009"}},"a416fadcb9fb4156afca5c174eccab3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_82db5c134b85429999dc55c20544826d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [00:00&lt;00:00, 2.81MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6993bb18fcb745098936a6fbc979891e"}},"a071a26bcc314b9282ac1c347002bf74":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ddc9f8a82c104ae8866517ab56176009":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"82db5c134b85429999dc55c20544826d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6993bb18fcb745098936a6fbc979891e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0a1fe8256e0f431182dea652cea52096":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ec53981a506b4530bec184b20c3f3ec2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2615f6e039fe4dbab25b285738eba159","IPY_MODEL_0f4a6adbcdb048a1ba63905a005b4ce5"]}},"ec53981a506b4530bec184b20c3f3ec2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2615f6e039fe4dbab25b285738eba159":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_624ae133bab947c8810e1b1337d8f610","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":481,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":481,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f7b8f2a1906848db8e14731af3add68d"}},"0f4a6adbcdb048a1ba63905a005b4ce5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d2aed54921584c7391ed28fd4596f795","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 481/481 [28:40&lt;00:00, 3.58s/B]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b057116d1b67469d900757ed191342db"}},"624ae133bab947c8810e1b1337d8f610":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f7b8f2a1906848db8e14731af3add68d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d2aed54921584c7391ed28fd4596f795":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b057116d1b67469d900757ed191342db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19fdac31a5ca44ca8730f0181b65c0f6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6ca377b4bbeb49c4ba73068ea9969e05","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_457260f92c85455784e2b0c7a62c2b36","IPY_MODEL_3368743db5b04418a28769673d41540a"]}},"6ca377b4bbeb49c4ba73068ea9969e05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"457260f92c85455784e2b0c7a62c2b36":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c0a60d9703204f2a847c94118a69f76f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":501200538,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":501200538,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ce853c938e4b407e85716b78e3de4f49"}},"3368743db5b04418a28769673d41540a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_34158558fac54e708c45c3fa203033a4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 501M/501M [00:12&lt;00:00, 38.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_13ab2b1929034ae7af088d7cee4279a1"}},"c0a60d9703204f2a847c94118a69f76f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ce853c938e4b407e85716b78e3de4f49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"34158558fac54e708c45c3fa203033a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"13ab2b1929034ae7af088d7cee4279a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"wt7JHVXQhh1T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621372866069,"user_tz":420,"elapsed":31782,"user":{"displayName":"Kaleen Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjok_63OtbONf0JKntnYC4yBHRKmSHha6vk0nl7uA=s64","userId":"17677293658466379584"}},"outputId":"1cdeadac-a709-4d67-8f34-de5a1cd811c6"},"source":["import os\n","import pandas as pd\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","cur_dir = \"/content/drive/MyDrive/Colab_Notebooks/NLP_244_Advanced_ML/final_project_socialiqa/socialiqa-nlp244\"\n","data_dir = \"socialiqa-train-dev\"\n","out_dir = \"out\"\n","\n","!pip install transformers"],"id":"wt7JHVXQhh1T","execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9e/5b80becd952d5f7250eaf8fc64b957077b12ccfe73e9c03d37146ab29712/transformers-4.6.0-py3-none-any.whl (2.3MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 9.0MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 36.4MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 36.0MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Installing collected packages: sacremoses, tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"01c37cd3"},"source":["File for trying out models on SocialIQA"],"id":"01c37cd3"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"78b296fb","executionInfo":{"status":"ok","timestamp":1621372868549,"user_tz":420,"elapsed":12540,"user":{"displayName":"Kaleen Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjok_63OtbONf0JKntnYC4yBHRKmSHha6vk0nl7uA=s64","userId":"17677293658466379584"}},"outputId":"70a0b7b7-8afa-4e62-e0d6-777f19b7509b"},"source":["file_train = os.path.join(cur_dir, \"socialiqa-train-dev/train.jsonl\")\n","file_dev = os.path.join(cur_dir, \"socialiqa-train-dev/dev.jsonl\")\n","\n","json_train = pd.read_json(path_or_buf=file_train, lines=True)\n","json_dev = pd.read_json(path_or_buf=file_dev, lines=True)\n","\n","# list of tuples (context, question, A, B++++, C)\n","train_data = [elem for elem in zip(json_train['context'].tolist(), \n","                                   json_train['question'].tolist(), \n","                                   json_train['answerA'].tolist(), \n","                                   json_train['answerB'].tolist(), \n","                                   json_train['answerC'].tolist())]\n","\n","dev_data = [elem for elem in zip(json_dev['context'].tolist(), \n","                                   json_dev['question'].tolist(), \n","                                   json_dev['answerA'].tolist(), \n","                                   json_dev['answerB'].tolist(), \n","                                   json_dev['answerC'].tolist())]\n","\n","len(train_data), len(dev_data)"],"id":"78b296fb","execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(33410, 1954)"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iCy8_aL5C0jN","executionInfo":{"status":"ok","timestamp":1621372869071,"user_tz":420,"elapsed":11413,"user":{"displayName":"Kaleen Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjok_63OtbONf0JKntnYC4yBHRKmSHha6vk0nl7uA=s64","userId":"17677293658466379584"}},"outputId":"24802d81-ac9a-406f-89bf-e66dfd0351b6"},"source":["train_labels = []\n","dev_labels = []\n","with open(os.path.join(cur_dir, data_dir, \"train-labels.lst\")) as f:\n","    for line in f:\n","      train_labels.append(int(line.split()[0]))\n","\n","with open(os.path.join(cur_dir, data_dir, \"dev-labels.lst\")) as f:\n","    for line in f:\n","      dev_labels.append(int(line.split()[0]))\n","\n","train_labels = [label-1 for label in train_labels]\n","dev_labels = [label-1 for label in dev_labels]\n","\n","len(train_labels), len(dev_labels)"],"id":"iCy8_aL5C0jN","execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(33410, 1954)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"qwhiVU3OPwrU","executionInfo":{"status":"ok","timestamp":1621373000798,"user_tz":420,"elapsed":5234,"user":{"displayName":"Kaleen Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjok_63OtbONf0JKntnYC4yBHRKmSHha6vk0nl7uA=s64","userId":"17677293658466379584"}}},"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import RobertaModel, RobertaTokenizer"],"id":"qwhiVU3OPwrU","execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"KOIz47KoR2Np","executionInfo":{"status":"ok","timestamp":1621373338694,"user_tz":420,"elapsed":436,"user":{"displayName":"Kaleen Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjok_63OtbONf0JKntnYC4yBHRKmSHha6vk0nl7uA=s64","userId":"17677293658466379584"}}},"source":["class SocialiqaDataset(Dataset):\n","    \"\"\"\n","    This dataset class for socialiqa might be able to be generalized for \n","    HellaSwag and other tasks.\n","\n","    This is the context/question + multiple choice format, and each example\n","    consists of num choices lists of encoded strings. Note that the input will\n","    be encoded in this stage. prepare_batch will take care of padding across examples\n","    in the batch-level. \n","    \"\"\"\n","    def __init__(self, tokenizer, x, y):\n","        # x: list of tuples containing (context, question, answer1, answer2, answer3)\n","        # y: list of indices of the correct answer\n","        self.roberta_tokenizer = tokenizer\n","        self.x = x\n","        self.y = y\n","\n","    def __getitem__(self, idx):\n","        point = self.x[idx]\n","        input_context_question = [point[0] + self.roberta_tokenizer.sep_token + self.roberta_tokenizer.sep_token + point[1], point[0] + self.roberta_tokenizer.sep_token + self.roberta_tokenizer.sep_token + point[1], point[0] + self.roberta_tokenizer.sep_token + self.roberta_tokenizer.sep_token + point[1]]\n","        input_answers = [point[2], point[3], point[4]]\n","        encoded_text_train = self.roberta_tokenizer(input_context_question, input_answers, return_tensors='pt', padding=True)\n","        return (encoded_text_train, self.y[idx])\n","\n","    def __len__(self):\n","        return len(self.x)\n","\n","\n","def prepare_batch_MC(batch, tokenizer):\n","    \"\"\"\n","    This collate function will pad the batch to be the same length. This requires\n","    flattening, then unflattening for the multiple choice format.\n","    One example will be a list of length 'num choices', each element being a list\n","    of (encoded) tokens representing qustion/answer [sep] choicex\n","    \"\"\"\n","    # batch: [batch_size, (text, label)]\n","    batch_size = len(batch)\n","    print(f\"Batch size: {batch_size}\")\n","\n","    features, labels = zip(*batch)\n","    # features: tuple of length batch_size, \n","    #        each element is a dict with keys = [\"input_ids\", \"attention_mask\"]\n","    # labels: tuple of ints (0, 1, 2) of length batch_size\n","    num_choices = len(features[0][\"input_ids\"])\n","    \n","    # flatten\n","    flattened_features = [\n","            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n","        ]\n","    flattened_features = sum(flattened_features, [])\n","    # flattened_features list length num_choices*batch_size\n","\n","    batch = tokenizer.pad(\n","            flattened_features,\n","            padding=True,\n","            return_tensors=\"pt\",\n","        )\n","    \n","    # Un-flatten\n","    batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n","    return (batch, torch.tensor(labels, dtype=torch.int64))\n"],"id":"KOIz47KoR2Np","execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"C3Nvl8e59rDY","colab":{"base_uri":"https://localhost:8080/","height":165,"referenced_widgets":["bbe9c78b9d3b4090816e76eb76677776","eda0cf1487d440cfb910e8670fa45e9b","c8e2b385ee7949b68b94f594bf1c4701","bf8e9f7eb1da4a7ca479ca7830507adb","01152b8a64984744971fb30a68300df3","4d03102170eb486e9cd849854e826e90","c0a3d6f59ca94f0dba41abcb6c78cb1f","3a85b6e5ce8541e487f4ee46c9ae60e2","4f92834a27be470391e6282648571eb8","ce4150e4ea724ae5ad6fddef7388aace","daf149fe5b66438fa0f1f959faf2ba1f","b53c8e61bd724318a6838315f1515fe6","c0c0df82976e4ec690d2a4cbc0ac552f","9a87e0dc73b34137a2fb369afe16e999","08e9f664f2e148de810828f86bd88b6e","aee13d0d16c34798802d730a051fd6ed","8ad3ad42c1df492bb8d0504a2c481024","32252d95ad7c4651975e3cee27ee4e9d","66d839cabac145739b3e40f23bd1ed52","a416fadcb9fb4156afca5c174eccab3f","a071a26bcc314b9282ac1c347002bf74","ddc9f8a82c104ae8866517ab56176009","82db5c134b85429999dc55c20544826d","6993bb18fcb745098936a6fbc979891e"]},"executionInfo":{"status":"ok","timestamp":1621373349021,"user_tz":420,"elapsed":3529,"user":{"displayName":"Kaleen Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjok_63OtbONf0JKntnYC4yBHRKmSHha6vk0nl7uA=s64","userId":"17677293658466379584"}},"outputId":"dc0c6826-7760-489b-dc54-43a49618e2d8"},"source":["tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","dataset_train = SocialiqaDataset(tokenizer, train_data, train_labels)\n","dataset_dev = SocialiqaDataset(tokenizer, dev_data, dev_labels)"],"id":"C3Nvl8e59rDY","execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bbe9c78b9d3b4090816e76eb76677776","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4f92834a27be470391e6282648571eb8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ad3ad42c1df492bb8d0504a2c481024","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hnSNr4MYbjic","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621351488818,"user_tz":420,"elapsed":1310,"user":{"displayName":"Kaleen Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjok_63OtbONf0JKntnYC4yBHRKmSHha6vk0nl7uA=s64","userId":"17677293658466379584"}},"outputId":"a74751c9-a326-4cb6-86e5-d9f4f40097f0"},"source":["x = dataset_train.__getitem__(0)[0]\n","y = dataset_train.__getitem__(0)[1]\n","x, y"],"id":"hnSNr4MYbjic","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'input_ids': tensor([[    0,   347, 35953,  1276,     7,    33,    10, 18906,     8,  4366,\n","             69,   964,   561,     4,     2,     2,  6179,    74,  5763,   619,\n","             25,    10,   898,   116,     2,     2,  3341,  5190,     2,     1,\n","              1,     1],\n","         [    0,   347, 35953,  1276,     7,    33,    10, 18906,     8,  4366,\n","             69,   964,   561,     4,     2,     2,  6179,    74,  5763,   619,\n","             25,    10,   898,   116,     2,     2,  3341,  4959,   184,     2,\n","              1,     1],\n","         [    0,   347, 35953,  1276,     7,    33,    10, 18906,     8,  4366,\n","             69,   964,   561,     4,     2,     2,  6179,    74,  5763,   619,\n","             25,    10,   898,   116,     2,     2,   102,   205,  1441,     7,\n","             33,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1]])}, 0)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NH2TD7WRb06F","executionInfo":{"status":"ok","timestamp":1621224496238,"user_tz":420,"elapsed":332,"user":{"displayName":"Kaleen Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjok_63OtbONf0JKntnYC4yBHRKmSHha6vk0nl7uA=s64","userId":"17677293658466379584"}},"outputId":"5491671d-fb5c-4e94-f3b1-f963fc791fe9"},"source":["print(tokenizer.decode(x['input_ids'][0]), \"\\n\", tokenizer.decode(x['input_ids'][1]), \"\\n\", tokenizer.decode(x['input_ids'][2]))"],"id":"NH2TD7WRb06F","execution_count":null,"outputs":[{"output_type":"stream","text":["<s>Cameron decided to have a barbecue and gathered her friends together.</s></s>How would Others feel as a result?</s></s>like attending</s><pad><pad><pad> \n"," <s>Cameron decided to have a barbecue and gathered her friends together.</s></s>How would Others feel as a result?</s></s>like staying home</s><pad><pad> \n"," <s>Cameron decided to have a barbecue and gathered her friends together.</s></s>How would Others feel as a result?</s></s>a good friend to have</s>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0lTitxJ1JPPU","executionInfo":{"status":"ok","timestamp":1621373368914,"user_tz":420,"elapsed":465,"user":{"displayName":"Kaleen Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjok_63OtbONf0JKntnYC4yBHRKmSHha6vk0nl7uA=s64","userId":"17677293658466379584"}}},"source":["train_loader = DataLoader(dataset_train, batch_size=2, shuffle=True, collate_fn=lambda batch: prepare_batch_MC(batch, tokenizer))\n","val_loader = DataLoader(dataset_dev, batch_size=1, shuffle=False)\n"],"id":"0lTitxJ1JPPU","execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"CnQabiyOKFvK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621373797623,"user_tz":420,"elapsed":426,"user":{"displayName":"Kaleen Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjok_63OtbONf0JKntnYC4yBHRKmSHha6vk0nl7uA=s64","userId":"17677293658466379584"}},"outputId":"d49f7e89-191e-450c-b00f-ca3d255de21b"},"source":["for i, batch in enumerate(train_loader):\n","    print(batch)\n","    break"],"id":"CnQabiyOKFvK","execution_count":9,"outputs":[{"output_type":"stream","text":["Batch size: 2\n","({'input_ids': tensor([[[    0, 16804,  9728,    39,  1441,    11,  9397,     5,  6231,   137,\n","             51,  1381,   402,    51,   303,    11,     5,  3418,     4,     2,\n","              2,  2264,    40,  2618,   236,     7,   109,   220,   116,     2,\n","              2, 19746,    10, 11637,     2,     1],\n","         [    0, 16804,  9728,    39,  1441,    11,  9397,     5,  6231,   137,\n","             51,  1381,   402,    51,   303,    11,     5,  3418,     4,     2,\n","              2,  2264,    40,  2618,   236,     7,   109,   220,   116,     2,\n","              2, 33869,    24,     2,     1,     1],\n","         [    0, 16804,  9728,    39,  1441,    11,  9397,     5,  6231,   137,\n","             51,  1381,   402,    51,   303,    11,     5,  3418,     4,     2,\n","              2,  2264,    40,  2618,   236,     7,   109,   220,   116,     2,\n","              2, 19746,    10,  6921,   324,     2]],\n","\n","        [[    0,  1627,  1178,   770,     7,  2540, 17279,  9422,    98,    37,\n","            156,   686,     7,   120,    69,    10,  2335,     4,     2,     2,\n","           6179,    74,  8740,   619,    25,    10,   898,   116,     2,     2,\n","            281,  5074,     2,     1,     1,     1],\n","         [    0,  1627,  1178,   770,     7,  2540, 17279,  9422,    98,    37,\n","            156,   686,     7,   120,    69,    10,  2335,     4,     2,     2,\n","           6179,    74,  8740,   619,    25,    10,   898,   116,     2,     2,\n","            281, 21460,     2,     1,     1,     1],\n","         [    0,  1627,  1178,   770,     7,  2540, 17279,  9422,    98,    37,\n","            156,   686,     7,   120,    69,    10,  2335,     4,     2,     2,\n","           6179,    74,  8740,   619,    25,    10,   898,   116,     2,     2,\n","            281,  1372,     2,     1,     1,     1]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n","\n","        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]]])}, tensor([1, 2]))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jF3OMy7TY6Uv","executionInfo":{"status":"ok","timestamp":1621374832550,"user_tz":420,"elapsed":405,"user":{"displayName":"Kaleen Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjok_63OtbONf0JKntnYC4yBHRKmSHha6vk0nl7uA=s64","userId":"17677293658466379584"}}},"source":["class Multiple_Choice_Model(nn.Module):\n","    def __init__(self, roberta_model: RobertaModel, dropout: float = None):\n","          super(Multiple_Choice_Model, self).__init__()\n","          self.roberta = roberta_model\n","          self.dropout = nn.Dropout(self.roberta.config.hidden_dropout_prob)\n","          self.classifier = nn.Linear(self.config.hidden_size, 1)\n","\n","    def forward(self, input_ids: torch.tensor, attention_mask: torch.tensor, labels=None):\n","          num_choices = input_ids.shape[1] \n","          flat_input_ids = input_ids.view(-1, input_ids.size(-1))\n","          flat_attention_mask = attention_mask.view(-1, attention_mask.size(-1))\n","\n","          outputs = self.roberta(\n","              flat_input_ids,\n","              attention_mask=flat_attention_mask,\n","          )\n","          pooled_output = outputs[1] \n","\n","          pooled_output = self.dropout(pooled_output)\n","          logits = self.classifier(pooled_output)\n","          reshaped_logits = logits.view(-1, num_choices)\n","\n","          loss = None\n","          loss_fct = nn.CrossEntropyLoss()\n","          loss = loss_fct(reshaped_logits, labels)\n","\n","          return loss, reshaped_logits"],"id":"jF3OMy7TY6Uv","execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4O4_UkdHzu6","executionInfo":{"status":"ok","timestamp":1621374698709,"user_tz":420,"elapsed":516,"user":{"displayName":"Kaleen Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjok_63OtbONf0JKntnYC4yBHRKmSHha6vk0nl7uA=s64","userId":"17677293658466379584"}}},"source":["class Trainer(object):\n","    \"\"\"\n","    Trainer for training a multiple choice classification model\n","    \"\"\"\n","\n","    def __init__(self, model, optimizer, device=\"cpu\"):\n","        self.model = model.to(device)\n","        self.optimizer = optimizer\n","        self.device = device\n","\n","    def _print_summary(self):\n","        print(self.model)\n","        print(self.optimizer)\n","\n","    def train(self, loader):\n","        \"\"\"\n","        Run a single epoch of training\n","        \"\"\"\n","\n","        self.model.train() # Run model in training mode\n","        loss = None\n","        for i, batch in tqdm(enumerate(loader)):\n","            # clear gradient\n","            self.optimizer.zero_grad() \n","\n","            # input_ids shape: (batch_size, num_choices, sequence_length)\n","            input_ids = batch[0]['input_ids'].to(self.device)\n","            # input_ids shape: (batch_size, num_choices, sequence_length)\n","            attention_mask = batch[0]['attention_mask'].to(self.device)\n","            # labels shape: (batch_size, )\n","            labels = batch[1].to(self.device)\n","\n","            outputs = model(input_ids=input_ids, \n","                            attention_mask=attention_mask,\n","                            labels=labels,\n","                            slot_labels=slot_labels)\n","            loss, logits = outputs[0], outputs[1]\n","            \n","            # back propagation\n","            loss.backward()\n","            # do gradient descent\n","            self.optimizer.step() \n","\n","        # Just returning the last loss\n","        return loss\n","\n","    def evaluate(self, loader):\n","        \"\"\"\n","        Evaluate the model on a validation set.\n","        Only do batch size = 1.\n","        \"\"\"\n","\n","        self.model.eval() # Run model in eval mode (disables dropout layer)\n","        slot_loss = None\n","        relation_loss = None\n","        with torch.no_grad(): # Disable gradient computation - required only during training\n","            for i, batch in tqdm(enumerate(loader)):\n","                # input_ids shape: (batch_size, num_choices, sequence_length)\n","                input_ids = batch[0]['input_ids'].to(self.device)\n","                # input_ids shape: (batch_size, num_choices, sequence_length)\n","                attention_mask = batch[0]['attention_mask'].to(self.device)\n","                # labels shape: (batch_size, )\n","                labels = batch[1].to(self.device)\n","\n","                outputs = model(input_ids=input_ids, \n","                                attention_mask=attention_mask,\n","                                labels=labels,\n","                                slot_labels=slot_labels)\n","                loss, logits = outputs[0], outputs[1]\n","\n","        # Just returning the last loss\n","        return loss\n","\n","    def get_model_dict(self):\n","        return self.model.state_dict()\n","\n","    def run_training(self, train_loader, valid_loader, n_epochs=3):\n","        # Useful for us to review what experiment we're running\n","        # Normally, you'd want to save this to a file\n","        # self._print_summary()\n","\n","        for i in range(n_epochs):\n","            epoch_loss_train = self.train(train_loader)\n","            epoch_loss_valid = self.evaluate(valid_loader)\n","            print(f\"Epoch {i}\")\n","            print(f\"Train loss: {epoch_loss_train}\")\n","            print(f\"Valid loss: {epoch_loss_valid}\")"],"id":"k4O4_UkdHzu6","execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fHa_fx2Cl60k","executionInfo":{"status":"ok","timestamp":1621376881605,"user_tz":420,"elapsed":2331,"user":{"displayName":"Kaleen Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjok_63OtbONf0JKntnYC4yBHRKmSHha6vk0nl7uA=s64","userId":"17677293658466379584"}},"outputId":"f9c6b063-7ce5-439d-cfb2-4b8c864202fc"},"source":["roberta_base = RobertaModel.from_pretrained('roberta-base')\n","type(roberta_base)"],"id":"fHa_fx2Cl60k","execution_count":20,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["transformers.models.roberta.modeling_roberta.RobertaModel"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":552,"referenced_widgets":["0a1fe8256e0f431182dea652cea52096","ec53981a506b4530bec184b20c3f3ec2","2615f6e039fe4dbab25b285738eba159","0f4a6adbcdb048a1ba63905a005b4ce5","624ae133bab947c8810e1b1337d8f610","f7b8f2a1906848db8e14731af3add68d","d2aed54921584c7391ed28fd4596f795","b057116d1b67469d900757ed191342db","19fdac31a5ca44ca8730f0181b65c0f6","6ca377b4bbeb49c4ba73068ea9969e05","457260f92c85455784e2b0c7a62c2b36","3368743db5b04418a28769673d41540a","c0a60d9703204f2a847c94118a69f76f","ce853c938e4b407e85716b78e3de4f49","34158558fac54e708c45c3fa203033a4","13ab2b1929034ae7af088d7cee4279a1"]},"id":"2QyKRRNydoJ3","executionInfo":{"status":"error","timestamp":1621375169603,"user_tz":420,"elapsed":15683,"user":{"displayName":"Kaleen Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjok_63OtbONf0JKntnYC4yBHRKmSHha6vk0nl7uA=s64","userId":"17677293658466379584"}},"outputId":"ba16ba71-179d-45bc-b2b7-9c04e40cd03c"},"source":["roberta_base = RobertaModel.from_pretrained('roberta-base')\n","mc_model = Multiple_Choice_Model(roberta_base)\n","from transformers import AdamW\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","mc_model.to(device)\n","mc_model.train()\n","\n","# 'W' stands for 'Weight Decay fix\"\n","# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","optimizer = AdamW(mc_model.parameters(), lr=5e-5)"],"id":"2QyKRRNydoJ3","execution_count":19,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a1fe8256e0f431182dea652cea52096","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19fdac31a5ca44ca8730f0181b65c0f6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-946f07b700bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mroberta_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'roberta-base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmc_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiple_Choice_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroberta_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-b1528550d7bb>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, roberta_model, dropout)\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroberta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroberta_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroberta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dropout_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    946\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 948\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Multiple_Choice_Model' object has no attribute 'config'"]}]},{"cell_type":"code","metadata":{"id":"n_xhloZnfXal"},"source":[""],"id":"n_xhloZnfXal","execution_count":null,"outputs":[]}]}